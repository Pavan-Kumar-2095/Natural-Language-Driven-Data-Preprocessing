{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3641ba9-267c-4866-86f2-6e8b3e9ca85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab235fc2-b788-42a1-b95a-d0e204f0616c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4800</td>\n",
       "      <td>4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ensure dataset has no duplicate rows</td>\n",
       "      <td>REMOVE_DUPLICATES_ROWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>54</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sentence                  intent\n",
       "count                                   4800                    4800\n",
       "unique                                  2021                       8\n",
       "top     ensure dataset has no duplicate rows  REMOVE_DUPLICATES_ROWS\n",
       "freq                                      54                     600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/intent_dataset_ml_diverse.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a8a338-8367-4980-8141-0a2427bd2c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent\n",
       "REMOVE_DUPLICATES_ROWS    600\n",
       "FILL_NA                   600\n",
       "LABEL_ENCODE_COLUMN       600\n",
       "STANDARDIZE_COLUMN        600\n",
       "TYPE_CAST                 600\n",
       "DROP_COLUMN               600\n",
       "NORMALIZE_COLUMN          600\n",
       "REMOVE_OUTLIERS_COLUMN    600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.intent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bf3266-204a-4bc1-8ace-f4950325a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DROP_COLUMN' 'FILL_NA' 'LABEL_ENCODE_COLUMN' 'NORMALIZE_COLUMN'\n",
      " 'REMOVE_DUPLICATES_ROWS' 'REMOVE_OUTLIERS_COLUMN' 'STANDARDIZE_COLUMN'\n",
      " 'TYPE_CAST']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df[\"sentence\"]\n",
    "y = df[\"intent\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33cfb5f-ea52-4bd2-a83a-f767cb14e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent\n",
      "REMOVE_DUPLICATES_ROWS    600\n",
      "FILL_NA                   600\n",
      "LABEL_ENCODE_COLUMN       600\n",
      "STANDARDIZE_COLUMN        600\n",
      "TYPE_CAST                 600\n",
      "DROP_COLUMN               600\n",
      "NORMALIZE_COLUMN          600\n",
      "REMOVE_OUTLIERS_COLUMN    600\n",
      "Name: count, dtype: int64\n",
      "Classes: ['DROP_COLUMN' 'FILL_NA' 'LABEL_ENCODE_COLUMN' 'NORMALIZE_COLUMN'\n",
      " 'REMOVE_DUPLICATES_ROWS' 'REMOVE_OUTLIERS_COLUMN' 'STANDARDIZE_COLUMN'\n",
      " 'TYPE_CAST']\n",
      "TF-IDF train shape: (3840, 807)\n",
      "TF-IDF test shape: (960, 807)\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           DROP_COLUMN       1.00      1.00      1.00       120\n",
      "               FILL_NA       1.00      1.00      1.00       120\n",
      "   LABEL_ENCODE_COLUMN       1.00      1.00      1.00       120\n",
      "      NORMALIZE_COLUMN       1.00      1.00      1.00       120\n",
      "REMOVE_DUPLICATES_ROWS       1.00      1.00      1.00       120\n",
      "REMOVE_OUTLIERS_COLUMN       1.00      1.00      1.00       120\n",
      "    STANDARDIZE_COLUMN       1.00      1.00      1.00       120\n",
      "             TYPE_CAST       1.00      1.00      1.00       120\n",
      "\n",
      "              accuracy                           1.00       960\n",
      "             macro avg       1.00      1.00      1.00       960\n",
      "          weighted avg       1.00      1.00      1.00       960\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[120   0   0   0   0   0   0   0]\n",
      " [  0 120   0   0   0   0   0   0]\n",
      " [  0   0 120   0   0   0   0   0]\n",
      " [  0   0   0 120   0   0   0   0]\n",
      " [  0   0   0   0 120   0   0   0]\n",
      " [  0   0   0   0   0 120   0   0]\n",
      " [  0   0   0   0   0   0 120   0]\n",
      " [  0   0   0   0   0   0   0 120]]\n",
      "Sentence:\n",
      " ensure dataset has no duplicate rows\n",
      "Label (encoded): 4\n",
      "Label (decoded): REMOVE_DUPLICATES_ROWS\n",
      "\n",
      "TF-IDF tokens and weights:\n",
      "ensure : 0.3255\n",
      "dataset : 0.2512\n",
      "has : 0.3255\n",
      "no : 0.3255\n",
      "duplicate : 0.2304\n",
      "rows : 0.2525\n",
      "ensure dataset : 0.3255\n",
      "dataset has : 0.3255\n",
      "has no : 0.3255\n",
      "no duplicate : 0.3255\n",
      "duplicate rows : 0.2797\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# =========================\n",
    "# 2️⃣ Load / Inspect Data\n",
    "# =========================\n",
    "# Example:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "# Columns: 'sentence', 'intent'\n",
    "\n",
    "\n",
    "df = df.dropna(subset=[\"sentence\", \"intent\"])\n",
    "df = df[df[\"sentence\"].str.strip() != \"\"]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df['intent'].value_counts())\n",
    "\n",
    "X = df[\"sentence\"]\n",
    "y = df[\"intent\"]\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    stratify=y_encoded,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1,2),\n",
    "    min_df=3,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF train shape:\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF test shape:\", X_test_tfidf.shape)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    C=1.0,\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\"\n",
    ")\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Optional confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "def inspect_sample(i, X, X_tfidf, y, vectorizer):\n",
    "    \"\"\"\n",
    "    Inspect a single sample in train/test:\n",
    "    - Original sentence\n",
    "    - Encoded label\n",
    "    - TF-IDF tokens with weights\n",
    "    \"\"\"\n",
    "    print(\"Sentence:\\n\", X.iloc[i])\n",
    "    print(\"Label (encoded):\", y[i])\n",
    "    print(\"Label (decoded):\", label_encoder.inverse_transform([y[i]])[0])\n",
    "\n",
    "    row = X_tfidf[i]\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    indices = row.indices\n",
    "    values = row.data\n",
    "\n",
    "    print(\"\\nTF-IDF tokens and weights:\")\n",
    "    for token, value in zip([feature_names[idx] for idx in indices], values):\n",
    "        print(token, \":\", round(value, 4))\n",
    "\n",
    "# Example: inspect row 1\n",
    "inspect_sample(1, X_train, X_train_tfidf, y_train, vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c70bd9c-d7e0-4add-9723-300faff7f747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save vectorizer\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Save trained classifier\n",
    "joblib.dump(clf, \"logistic_classifier.pkl\")\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545b5c22-0268-4e92-bf6f-83523739f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved objects\n",
    "import joblib\n",
    "\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "clf = joblib.load(\"logistic_classifier.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f189810c-0e0e-4d13-879a-28e5273d1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: fillna with mean\n",
      "Predicted Intent: FILL_NA\n",
      "Probability of predicted intent: 0.764\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "new_sentences = [\"fillna with mean\"]\n",
    "\n",
    "# Transform new sentences\n",
    "X_new_tfidf = vectorizer.transform(new_sentences)\n",
    "\n",
    "# Predict encoded labels\n",
    "y_pred_encoded = clf.predict(X_new_tfidf)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = clf.predict_proba(X_new_tfidf)\n",
    "\n",
    "for sentence, label, proba, pred_encoded in zip(new_sentences, y_pred_labels, y_pred_proba, y_pred_encoded):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted Intent: {label}\")\n",
    "    \n",
    "    # Probability of the guessed intent only\n",
    "    predicted_prob = round(proba[pred_encoded], 3)\n",
    "    print(f\"Probability of predicted intent: {predicted_prob}\")\n",
    "    print(\"------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37a9ad-cb17-4bd5-9357-9bf03faa5bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6feaeb1-993a-483a-a9b5-321638da66b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
